[{"content":"So you want to do some analyses, but don\u0026rsquo;t know where to start You have come to the right place!!\nFrom a guide on how to run programs, to little tips and tricks to make your life easier, you will find it on this website.\nFor brand new lab members If you are brand new to this lab, read this page from top to bottom.\nIf you only want to know about a specific topic, you can search for things in the search bar at the top right hand corner, or alterntaively, you can look through each tab/section of this web site to find the right thing.\nBackground readings We want anyone who starts out to have a basic knowledge of the following topics, and we highly recommend you take your time reading these topics:\n Basic Software Carpentry topics (R, GIT, and BASH) Association analysis Common file formats, where to find them, and how to use them  Where to ask for help At first instance, look for topics on this website.\nIf you find what you are looking for: Great!! Carry on with your life.\nBut if you don\u0026rsquo;t, don\u0026rsquo;t panic \u0026ndash; take these steps:\n Google your problem with relevant keywords like your program and error messages \u0026ndash; usually you will find something on Wikipedia or StackOverflow Ask for help or ask your question(s) on the \u0026ldquo;howdoi\u0026rdquo; channel on our lab Slack channel \u0026ndash; someone will be able to give you some good suggestions Ask the person who have done your analysis (or done something similar) before If all of the above fails, work it out yourself or abandon the problem If you find a solution, write up a post and add it to this website for future reference  Who do I ask to get help with \u0026ldquo;X\u0026rdquo; Here is an incomplete list of topics people are familiar with in our lab.\nMake sure to direct specific questions when you are asking for help:\n   Member R bash git GNU Make SnakeMake GWAS PLINK WGS Ancient DNA VCF General busy-ness Response time     Anna 🙆‍♀️ 🙆‍♀️ 🙆‍♀️ 🙅‍♀️ 🙅‍♀️ 🙆‍♀️ 🙆‍♀️ 🙆‍♀️ 🐓 🙆‍♀️ 👊 🐌🐌   Murray 🙆‍♂️ 🙆‍♂️ 🙆‍♂️ 🙅‍♂️ 🙆‍♂️ 🙆‍♂️ 🙆‍♂️ 🙆‍♂️ 🐒 🙆‍♂️ 🔥🔥🔥 🐌🐌   Riku 🙆‍♂️ 🙆‍♂️ 🙆‍♂️ 🙆‍♂️ 💩 👌 🙆‍♂️ 🙅‍♂️ 🐒 🙆‍♂️ 🕺🕺🕺 🐌    ","description":"","id":0,"section":"docs","tags":null,"title":"Getting Started","uri":"https://merrimanlab.github.io/docs/getting_started/"},{"content":"Requirements and prerequisites Here is a list of requirements that you will need in order to run this tool (relatively) smoothly.\nIf you have access to the Department of Biochemistry server, you should have little to no problems to meet these requrirements.\nSoftware You will need the following software to run this tool:\n Latest version of R Locus Zoom code from GitHub bcftools plink version 1.90 or later  Data You will need the following data to run this tool:\n 1000 Genomes Project Phase 3 reference data UCSC gene region information Summary level data with the following information:  Chromosome Position rsID Measure of significance (P or BF)    Optional data Optionally, you may provide the following:\n Output from MAGMA (for colouring the genes based on MAGMA significance)  ","description":"","id":1,"section":"docs","tags":null,"title":"Before You Begin","uri":"https://merrimanlab.github.io/docs/locuszooms/before_you_begin/"},{"content":"Make Locus Zoom-like plots with your own LD matrix This script creates an R function to create regional Manhattan plots with points coloured according to LD and genes annotated beneath.\nInput file format You will need at least two files to generate a Locus Zoom (LZ) plot: GWAS summary stats file, and a \u0026ldquo;gene\u0026rdquo; file.\nThe LD file can be generated on the fly, as long as you have access to the 1000GP reference data and the correct tools to calculate the LD (see Before you begin).\nPlease also note that the column names of the required files must match exactly to those specified below, so please take your time to check your headers and edit it to match with the specification.\nGWAS summary statistics Though you may have more information in your GWAS summary statistics, you only need the following four columns:\n   Column name Description     CHR Chromosome number of the variant   SNP rsID of the variant   BP Base position of the variant   P P-value of the variant    Instead of using P as significance, you may use logBF (e.g. from a trans-ancestry meta-analysis that used MANTRA).\nGene file A file of the genes within the region for use in the annotation step.\nThis file must have four columns:\n   Column name Description     Gene Gene name   Chrom Chromosome number of the gene   Start Start position of the gene   End End position of the gene    The UCSC_GRCh37_Genes_UniqueList.txt file is provided with the code.\nLD file This is a file that contains the LD between the SNP to be labelled (top-hit / SNP of interest) and the SNPs included in the GWAS summary statistics.\nThis file must contain the following two columns:\n   Column name Description     SNP_B List of all the SNPs in the region of interest   R2 The r2 LD-value of each SNP with the SNP of interest    The SNP names of the LD file must match the SNP names in the GWAS summary statistics file.\nTherefore, we recommend you to use rsID wherever possible to match with the 1000GP reference data (used to calculate the LD).\nTo calculate the LD yourself, follow the code below:\n1 2  bcftools view -r CHR:START-END /path/to/reference/chr/vcf.gz -Oz -o /path/to/output/tmp.vcf.gz plink1.9 --vcf /path/to/output/tmp.vcf.gz --allow-no-sex --snps-only --r2 inter-chr --ld-snp \u0026lt;rsid-of-interest\u0026gt; --ld-window-r2 0 --out /path/to/output/ld_file   where:\n   Column name Description     CHR Chromosome number   START Start position of the region of interest   END End position of the region of interest   rsid-of-interest rsID of interest (usually the lead variant)    For more information on why this could be useful, take a look at Generate multiple LZ plots.\nExamples Simple Locus Zoom You will be able to run the following code and produce the same Locus Zoom plot using the example data set from the GitHub repo.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  # Load necessary files into R Example.assoc.linear \u0026lt;- read.delim(\u0026#34;Example.assoc.linear\u0026#34;, stringsAsFactors = FALSE, header = TRUE) Example.ld \u0026lt;- read.table(\u0026#34;Example.ld\u0026#34;, stringsAsFactors = FALSE, header = TRUE) UCSC_GRCh37_Genes_UniqueList.txt \u0026lt;- read.delim(\u0026#34;Example.genes\u0026#34;, stringsAsFactors = FALSE, header = TRUE) # Load the locuszoom function into R source(\u0026#34;functions/locus_zoom.R\u0026#34;) # Create a LocusZoom-like plot locus.zoom(data = Example.assoc.linear, region = c(16, 53340000, 54550000), offset_bp = 0, ld.file = Example.ld, genes.data = UCSC_GRCh37_Genes_UniqueList.txt, plot.title = \u0026#34;Association of FTO with BMI in Europeans\u0026#34;, file.name = \u0026#34;Example.jpg\u0026#34;, secondary.snp = c(\u0026#34;rs1121980\u0026#34;, \u0026#34;rs8060235\u0026#34;), secondary.label = TRUE)   Locus Zoom with coloured genes based on MAGMA output This is not reproducible from the example data.\n1 2 3 4 5 6 7 8  locus.zoom(data = EUR_meta_full1_clean_rsid.nfiltered_chr7, gene = \u0026#34;MLXIPL\u0026#34;, offset_bp = 500000, genes.data = UCSC_GRCh37_Genes_UniqueList, plot.title = \u0026#34;Association of MLXIPL with gout in Europeans\u0026#34;, file.name = \u0026#34;alternateExample.jpg\u0026#34;, genes.pvalue = European_GWAS_2020_test.genes_named, colour.genes = TRUE)   ","description":"","id":2,"section":"docs","tags":null,"title":"How to generate LZ plot","uri":"https://merrimanlab.github.io/docs/locuszooms/generating_single_locus_zooms/"},{"content":"Make multiple Locus Zoom plots This is a general guide and recommendation on how to make multiple Locus Zooms.\nLoop the locus.zoom() call Probably the best way to make multiple Locus Zoom plots is to loop the function call to locus.zoom().\nInputs that change between different Locus Zoom plots are:\n SNP of interest/Gene of interest/Region of interest LD information of the region  Since the LD can be calculated on-the-fly, if you have a vector of SNPs/genes/regions of interest, you will be able to create a simple loop like so:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  variants = c(\u0026#34;rs1121980\u0026#34;, \u0026#34;rs8060235\u0026#34;) output_filenames = paste(variants, \u0026#34;.jpg\u0026#34;, sep = \u0026#39;\u0026#39;) for(i in 1:length(variants)) { locus.zoom(data = Example.assoc.linear, snp = variants[i], offset_bp = 500000, genes.data = UCSC_GRCh37_Genes_UniqueList.txt, plot.title = \u0026#34;Association of FTO with BMI in Europeans\u0026#34;, file.name = output_filenames[i], secondary.snp = variants, secondary.label = TRUE, ignore.lead = TRUE) }   Note here that the secondary.snp option has been set to the vector of variants of interest, and the ignore.lead option has been enabled. By passing the vector of interest to the secondary.snp option, it allows locus.zoom() to plot any SNPs of interest within the region of the plot, as well as the SNPs you are interested in.\nIn order to make sure the SNP of interest is colored correctly based on its LD, the ignore.lead option has been set. If this option wasn\u0026rsquo;t set, then the LD information of the top SNP in that region would always be used instead of the LD information of the SNP of interest that you wanted.\nFor regions of interest, we recommend you put the regions into a data frame with the following columns and pass each row to the function with a similar loop as above:\n   Options Description     chr Chromosome   start Start position of region   end End position of region    LD calculation \u0026ndash; on-the-fly, or pre-calculated? One thing to consider when generating multiple Locus Zoom plots is how you want to pass the LD information to the function.\nIn most cases, on-the-fly LD calculation will work. However, when your SNP of interest is not present in the reference data, there is no way to calculate the LD between the SNP of interest with all other variants in the region.\nPotential work around for this are:\n Use a different reference data for LD calculation Use a different (surrogate) marker\u0026rsquo;s LD information  Either way, unless you edit the locus.zoom() function yourself, you will have to calculate your own LD in order to work around this problem.\nManually including LD information One method is to generate the LDs of all of the SNPs of interest beforehand, load it all into a list, and loop through this list together with the locus.zoom() function.\nCalculate LD information The following code will generate LD for all the variants from a plink loci file in parallel:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  #! /bin/bash  # Script to generate LD of all the lead variants from plink loci output # Usage: bash /path/to/script plink.loci EUR ld_files LOCI=$1 ANCESTRY=$2 OUTPUT=$3 mkdir -p ${OUTPUT}/ld/${ANCESTRY} grep -v \u0026#34;^$\u0026#34; ${LOCI} | tr -s \u0026#39; \u0026#39; \u0026#39;\\t\u0026#39; | sed -e \u0026#39;s/^\\t//g\u0026#39; -e \u0026#39;s/^23/X/g\u0026#39; | cut -f1,3,4 | awk \u0026#39;NR \u0026gt; 1 {print $2, $1\u0026#34;:\u0026#34;$3 - 500000\u0026#34;-\u0026#34;$3 + 500000}\u0026#39; | tr \u0026#39; \u0026#39; \u0026#39;\\t\u0026#39; \u0026gt; ${LOCI}.query # Function to generate LD for each lead variant: run_ld() { line=$1 ancestry=$2 prefix=$(echo ${ancestry}_ | sed \u0026#39;s/LAT/AMR/g\u0026#39; | sed \u0026#39;s/TAMA_/AFR_AMR_EAS_EUR_/g\u0026#39;) rsid=$(echo ${line} | cut -d \u0026#39; \u0026#39; -f1 ) query=$(echo ${line} | cut -d \u0026#39; \u0026#39; -f2) chr=$(echo ${query} | cut -d \u0026#39;:\u0026#39; -f1) bcftools view -r ${query} /Volumes/archive/merrimanlab/reference_files/VCF/1000Genomes_vcf_files/Phase3_March2017/${ancestry}/${prefix}chr${chr}.*biallelic.vcf.gz -Oz -o ${OUTPUT}/ld/${ancestry}/${rsid}.vcf.gz plink1.9b4.9 --vcf ${OUTPUT}/ld/${ancestry}/${rsid}.vcf.gz --allow-no-sex --snps-only --r2 inter-chr --ld-snp ${rsid} --ld-window-r2 0 --out ${OUTPUT}/ld/${ancestry}/${rsid} } export -f run_ld cat ${LOCI}.query | parallel run_ld {} ${ANCESTRY}   First four columns of plink loci file are:\n   Column name Description     CHR Chromosome   F File number (ignored in the script)   SNP rsID   BP Base position of the SNP    This file doesn\u0026rsquo;t have to come directly from plink \u0026ndash; you can make your own loci file and pass it to the above script to generate your own LD.\nModify the loop Modify the loop as below:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  variants = c(\u0026#34;rs1121980\u0026#34;, \u0026#34;rs8060235\u0026#34;) # Import LD info of the variants (you may want to re-write this in purrr, if you want to): ld_files = paste(\u0026#39;path/to/ld/ancestry/\u0026#39;, variants, sep = \u0026#39;\u0026#39;) ld_files = paste(ld_files, \u0026#39;.ld\u0026#39;, sep = \u0026#39;\u0026#39;) ld_list = lapply(ld_files, function(x) read.table(x, stringsAsFactors = F, header = T)) output_filenames = paste(variants, \u0026#34;.jpg\u0026#34;, sep = \u0026#39;\u0026#39;) for(i in 1:length(variants)) { locus.zoom(data = Example.assoc.linear, snp = variants[i], ld.file = ld_list[[i]], offset_bp = 500000, genes.data = UCSC_GRCh37_Genes_UniqueList.txt, plot.title = \u0026#34;Association of FTO with BMI in Europeans\u0026#34;, file.name = output_filenames[i], secondary.snp = variants, secondary.label = TRUE, ignore.lead = TRUE) }   Now, the above code assumes the LD files are named \u0026lt;rsid\u0026gt;.ld, so if you have made a different LD using a surrogate SNP, then rename the surrogate SNP LD file so it matches up with the rsID of the SNP of interest.\n","description":"","id":3,"section":"docs","tags":null,"title":"Generate multiple LZ plots","uri":"https://merrimanlab.github.io/docs/locuszooms/multiple_lz_plots/"},{"content":"Stack LZ plots from multiple summary data This page is a general introduction to add multiple \u0026ldquo;panes\u0026rdquo; to your LZ plots, using multiple summary data.\nWhy use multiple summary data? Often we want to overlay LZ plots of the same region from different summary data sets (e.g. different traits or comparison with cis-eQTL).\nRather than generating separate LZ plots for each summary data and compare them, we have provided a way to add as many \u0026ldquo;panes\u0026rdquo; of LZ as you like into a single output, where each pane shows the LZ plot of a particular region for the summary data sets you have provided.\nPlotting multi-pane LZ plots Adding extra summary data In order to use multiple summary data for LZ, you have to pass the data sets as a list, rather than a data.frame:\n1 2 3 4  data1 = read.table(\u0026#39;path/to/data1.tsv\u0026#39;, sep = \u0026#39;\\t\u0026#39;, header = T, stringsAsFactors = F) data2 = read.table(\u0026#39;path/to/data2.tsv\u0026#39;, sep = \u0026#39;\\t\u0026#39;, header = T, stringsAsFactors = F) all_data = list(data1 = data1, data2 = data2)   The names of the data sets in the list are optional, but it will be used to label the panes so it is recommended to name them appropriately.\nMake sure all summary data in the list has the required columns and in the right format.\nPlotting the data Once the data sets are in a list variable, you can pass this list to the locus.zoom() function as before, but with the extra nplots = TRUE argument:\n1 2 3 4 5 6 7  locus.zoom(data = all_data, snp = \u0026#34;rs1121980\u0026#34;, offset_bp = 500000, genes.data = UCSC_GRCh37_Genes_UniqueList.txt, plot.title = \u0026#34;Association of FTO with BMI in Europeans\u0026#34;, file.name = \u0026#34;rs1121980.jpg\u0026#34;, nplots = TRUE)   The locus.zoom() function will pull out the relevant region from each of the summary data sets (assuming the region is present in both data sets) and plot it on top of each other.\nKey implementation details Lead SNP The lead SNP for all the panes are taken from the first data set in the list, and therefore this variant will be labelled in all of the panes, regardless of its significance in other summary data.\nIf the lead SNP is not present in the data set, it will not be labelled.\nLD calculation LD is calculated based on the lead SNP of the first data set, and this LD information is used for the other panes even if the lead SNP doesn\u0026rsquo;t exist in that particular data.\nThis is to allow for better comparison between the data sets. For example, you will be able to see which variant(s) in the second pane is in LD with the lead SNP in the first pane.\nCurrently, nothing is implemented to allow for independent LD per data set, so you won\u0026rsquo;t be able to make meaningful comparisons based on LD if the data sets you provided are from different ancestry.\n","description":"","id":4,"section":"docs","tags":null,"title":"LZ with multiple data sets","uri":"https://merrimanlab.github.io/docs/locuszooms/multi_pane_lz/"},{"content":"This post will cover some of the useful features in less that will let you look at any text-based document like a wizard!!\nScroll through page-wise As you may already know, you can use \u0026lt;space\u0026gt; to move one window forward in the document, but did you know there are ways to go back window-wise? Here is a table of some of the useful ways you can scroll through the document more efficiently (NOTE: ^ means press the \u0026lt;control\u0026gt; key with the following key):\n   Key(s) What it does How to remember     d or ^d Scroll forward half a window Go down half a window   u or ^u Scroll backward half a window Go up half a window   \u0026lt;space\u0026gt;, f, or ^f Scroll forward one window Go forward a window   b or ^b Scroll backward one window Go back a window    Search for keywords Wouldn\u0026rsquo;t it be nice if you could look for certain words or patterns in the document you have it open with less?\nWell, guess what - you can!!\n   Key(s) What it does How to remember     / + search pattern Search forward through the document N/A   ? + search pattern Search backward through the document Pressing \u0026lt;shift\u0026gt; key will reverse the command   n Go to the next line with your pattern Go to next search pattern   N Go to the previous line with your pattern Pressing \u0026lt;shift\u0026gt; key will reverse the command    Show only lines with certain pattern It is also possible to display only the lines that contain the matching pattern:\n   Key(s) What it does How to remember     \u0026amp; + search pattern Display only the lines with matching pattern N/A    Jump around the document Other than searching for patterns in the document, there are few ways you can jump around the document (e.g. to the beginning or to the end of the document).\n   Key(s) What it does How to remember     g Jump to the beginning of the document N/A   G Jump to the end of the document Pressing \u0026lt;shift\u0026gt; key will reverse the command   '' (two single quotes) Jump to the line you were at N/A (see below explanation of marks)    You can also save (or mark) specific line(s) and jump to that line at will:\n   Key(s) What it does How to remember     m + \u0026lt;letter\u0026gt; Save the position into \u0026lt;letter\u0026gt; of your choice Mark this position   ' + \u0026lt;letter\u0026gt; Jump to the position saved in \u0026lt;letter\u0026gt; N/A    The single quote ' is a special mark, where it will record the position you were at just before you jumped, so by pressing '', it will jump back to where you were just then.\nPass options while in less If you had forgotten to pass a command line option to less before you started it, it\u0026rsquo;s not too late for you to invoke it. You can add options to current less instance by typing - first, and then the option you wanted.\nFor example, if you want to wrap/unwrap long lines, you can press -S in less and press \u0026lt;enter\u0026gt;.\nShow help All of these are available in the help menu of less, which you can access by pressing h\n   Key(s) What it does How to remember     h Open the help page Help!!    ","description":"","id":5,"section":"post","tags":["bash","tips"],"title":"More on less","uri":"https://merrimanlab.github.io/post/2020-10-20-less/"},{"content":"Intro GNU parallel (commonly referred to as just parallel) is a command line tool that allows you to run multiple independent tasks at the same time by using the available cores on a computer.\nThis post will cover:\n How to use parallel Some useful features provided by parallel  Basic usage The basic syntax of a parallel command is:\nparallel \u0026quot;\u0026lt;command\u0026gt; {}\u0026quot; ::: \u0026lt;input\u0026gt; where \u0026lt;command\u0026gt; is the command you want to run in parallel for all the \u0026lt;input\u0026gt; you provide. The {} represents where in the \u0026lt;command\u0026gt; the \u0026lt;input\u0026gt; is substituted.\nFor example:\nparallel \u0026quot;echo my name is {}\u0026quot; ::: riku murray tanya ruth mandy will substitute {} with the names provided after the :::, and output the following (in whichever order parallel will output):\nmy name is riku my name is murray my name is tanya my name is ruth my name is mandy You can use {} as many times as you like:\nparallel \u0026quot;echo {}'s name is {}\u0026quot; ::: riku murray tanya ruth mandy will output:\nriku's name is riku murray's name is murray tanya's name is tanya ruth's name is ruth mandy's name is mandy Strictly speaking, quote marks are not necessary, but recommended (by me).\nAdditional features Multiple inputs If you have multiple sets of inputs you want to parallelise, you can add another set of input with ::: \u0026lt;input\u0026gt; after the first input, and then use a numbered {} to specify which input you want to use.\nFor example:\nparallel \u0026quot;touch {1}_{2}.txt\u0026quot; ::: 1 2 3 ::: A B C will output the following files:\n1_A.txt 1_B.txt 1_C.txt 2_A.txt 2_B.txt 2_C.txt 3_A.txt 3_B.txt 3_C.txt Note that parallel generates all possible combinations from the given inputs.\nxapply option There are situations where you don\u0026rsquo;t want to run the commands for all the combinations from your inputs, but rather run commands for the first item from each input together, then the second item, and so on. For example, echoing first and last name:\nparallel \u0026quot;echo {1} {2}\u0026quot; ::: riku murray tanya ::: takei cadzow major This will generate:\nriku takei riku cadzow riku major murray takei murray cadzow murray major tanya takei tanya cadzow tanya major which is not what we want parallel to do, because we want to associate the first item of first input with the first item of second input. To do this correctly, you can supply the --xapply option to parallel:\nparallel --xapply \u0026quot;echo {1} {2}\u0026quot; ::: riku murray tanya ::: takei cadzow major which will generate:\nriku takei murray cadzow tanya major Job control By default, parallel will use as many cores available on the computer to run the jobs. This may be problematic in situations where you want certain number of cores free for other programs to run, or to prevent the jobs using up all the memory by accident. You can specify the number of jobs to run with -j:\nparallel -j \u0026lt;N\u0026gt; \u0026quot;\u0026lt;command\u0026gt; {}\u0026quot; ::: \u0026lt;input\u0026gt; The \u0026lt;N\u0026gt; is the number of concurrent jobs you want parallel to run at the same time. Below is a guide on some of the values you can provide to the -j option:\n   Value Meaning     N Run up to N jobs at a time   -N Run total number of cores minus N jobs   N% Run as many jobs as N percent of the total number of cores   file Run as many jobs specified in a file (values as above)    Input manipulation When you pass file names (with or without absolute paths) to parallel, it is sometimes desirable to edit the file name in order to build outputs based on the input. For example, if you have an input.txt file and want an input.result.txt as an output, you can do the following to achieve this result:\nparallel \u0026quot;\u0026lt;command\u0026gt; {} \u0026gt; {.}.result.txt\u0026quot; ::: $(ls /path/to/files.txt) The extra . within the {} tells parallel to remove the extension of the input. Since the rest of the path is unchanged, *.result.txt file will appear in the same directory as the input (in this case, /path/to/).\nHere is a table of some of the things you can do to the input line:\n   Value Meaning     {.} File name without extension   {/} Basename of input (i.e. file name without the directory)   {//} Directory of input without the file name   {/.} Basename of input without extension    If you add a number to any of the above options, it will manipulate the Nth input. For example, {2.} will remove the file extension from the second input.\n","description":"","id":6,"section":"post","tags":["parallel","bash"],"title":"GNU parallel","uri":"https://merrimanlab.github.io/post/2020-10-19-parallel/"},{"content":"Intro Once you have finished Software Carpentry Git lesson, you should be able to do basic version controlling with Git. You would have learnt how to:\n Stage and commit your changes Make a remote GitHub repository Push and pull from your remote repository Solve merge conflicts  These skills are enough for you to get started with tracking and maintaining your own project, but once you start collaborating with others, you can run into trouble really quick. Even if you don\u0026rsquo;t encounter major problems, knowing a little bit more beyond SWC git lessons will help you streamline the process of how you maintain your repository.\nCollaborate with a fork, not a clone Towards the end of the SWC git lesson, you would have touched briefly on collaborating with others. In the lesson, you would have had to add your partner to your list of collaborators on GitHub, which allowed you to clone it to your computer for editing. However, in reality, the project manager/maintainer will not add you as a collaborator and allow you full access to the repo.\nInstead, you are encouraged to fork the repository onto your remote first, and then make changes to the forked repository. The difference between this approach compared to cloning is that you are able to change the repo as much as you like without accidentally breaking the original repository that you have forked from.\nFork vs. Clone To further clarify, a fork is a copy of the original repo (owned by someone else) that has been copied over to your remote account, which you are now the owner of (the forked repo). A clone is a copy of the original repo (owned by someone else) that has been copied to your local computer which you can edit, but still owned by someone else, and therefore you won\u0026rsquo;t be able to push your changes to the repo (unless you are a collaborator).\nSend changes with Pull Requests (PR) So, then, how do you add your changes to the original repo when you don\u0026rsquo;t have access to it?\nGitHub is smart enough to keep track of all the forked repos of the original repository, and when it finds out that there are differences between the original and the forked repo, it will ask if you want to \u0026ldquo;send a pull request\u0026rdquo;. A Pull Request (PR), as the name suggests, asks the original repo owner to pull the changes from your forked repo into their repo.\nA general rule of thumb is to limit a PR to changes that achieve a specific goal (e.g. to fix a particular bug).\nWhen a PR is made, the owner will be able to check the changes you have made to the repo, and decides to add (merge) it to the repo or reject it. PR gives that extra layer of checking and reviewing in order to prevent the program from breaking and reduce the chance of introducing bugs.\nHow PR works PRs work by comparing the changes between a specific \u0026ldquo;branch\u0026rdquo; of the original repo with a specific branch in your repo. When more changes are requested during the review process of your PR, you can simply add more commits to the particular branch on your fork, and the changes will automatically be reflected in the PR. This may sound convenient, but it can get very messy very quick if you don\u0026rsquo;t be careful.\nWhen PRs get messy Since PRs depend on the changes made to the branch, if you commit changes to that same branch without thinking, those changes will get added to the PR even if the changes are completely unrelated to the PR you have made.\nIn order to fix this, you will have to revert your commit, add the changes you were requested, wait for the changes to get merged, then somehow remember what changes you have made before reverting the commit - all the extra work you could have prevented, had you known about branches.\nBranches A branch is a temporary copy of the current state of the repo in a different \u0026ldquo;workspace\u0026rdquo;. In this newly created branch, you will be able to make changes and edit as you wish without affecting the state of the repo when you made the branch.\nSound familiar? That\u0026rsquo;s because a fork is a special type of branch.\nBranches allow you to work on different parts of the project without breaking the other parts, and keeps you in control of what changes are being made to the repo.\nCreate, delete, and switch branches To create a new branch:\ngit branch \u0026lt;branch-name\u0026gt; To delete a branch:\ngit branch -d \u0026lt;branch-name\u0026gt; In order to switch to a different branch, use the checkout command:\ngit checkout \u0026lt;branch-name\u0026gt; If you don\u0026rsquo;t know what branches are available, use git branch without a branch name and you should get a list of all the branches for your repo:\ngit branch Importance of branching Now, coming back to the messy PR example.\nIf, before you had sent a PR, you had created a branch (called bug-fix) with all the changes that, for example, fixed a bug in the program. Then, you would send a PR using the bug-fix branch, and not your main working branch. Since the bug-fix branch is self-contained and has nothing to do with other branches, you can now work on other parts of the project (hopefully in a new branch) and commit the changes as much as you like without affecting the bug-fix branch.\nWhen you are requested to add further changes to your bug-fix branch, then you would simply checkout the branch, make the changes, and commit the changes to the branch, and the changes will get reflected on the PR.\nSummary  Fork the repo for collaboration Make new branch for specific changes you want to make Send pull requests with specific branch  ","description":"","id":7,"section":"post","tags":["git"],"title":"Beyond Software Carpentry Git","uri":"https://merrimanlab.github.io/post/2020-10-16-beyond-swc-git/"},{"content":"What is Hugo? Hugo is a popular static site generator written in Go language. It\u0026rsquo;s static in the sense that the web pages do not change depending on who visits the site (for example, contents do not change for different user) \u0026ndash; all the contents displayed on the site are pre-defined. Given a bunch of markdown files, Hugo automatically convert those markdown files into HTML files that are ready for a web site.\nThe aim of this post is to give you an introduction on how Hugo works and how to make a new post for the website.\nPlease note that this post is a Hugo workflow, and there is another workflow based on R blogdown package that is geared more towards compiling RMarkdowns.\nInstall relevant files and programs Install Hugo Install the latest version of Hugo for your OS. If you have homebrew in MacOS, the following will install Hugo:\nbrew install hugo Download this blog Download the repository for this blog to a directory of your choice:\ncd /directory/of/your/choice git clone git@github.com:MerrimanLab/merrimanlab.github.io.git Structure of Hugo blogs The 2 directories you have to be aware of are:\n content/ public/  Content directory The content/ directory is where you put your markdown files in - i.e. your blog contents.\nYou will notice that the content directory is organised into several sub-directories, such as about/ and docs. These directories are the specific groupings the author of the blog has decided to make in order to organise the posts within the blog.\nYou can make your own \u0026ldquo;group\u0026rdquo; by making a new sub-directory and make it appear on the blog, but this is beyond the scope of this post.\nPublic directory The public/ directory is where Hugo places the converted HTML files in. In other words, this directory contains your web site.\nYou will notice that there are (or will be) directories within the public/ directory that matches with the content/ sub-directories (e.g. public/about/). Each of these sub-directories reflect the counterparts in the content/ directory and organised accordingly.\nHow do I make a new post? As you may have guessed already, in order to make a new blog post, the only thing you need to do is to create a markdown file and place it in the correct directory in content/.\nTo do this, use Hugo\u0026rsquo;s new command:\nhugo new content/path/to/content/new_post.md This will create a new_post.md file in the directory that you have specified. Ideally, you will want to add a date to your file name in order to prevent duplicate file names within the content/ directory.\nYou can now edit the markdown file as you wish.\nHow do I look at the post I just made? First, you will have to generate the website with Hugo:\nhugo The above command will create the public/ directory (if it isn\u0026rsquo;t present already) and everything required for a website in it. However, it will not show you what it looks like. To look at what the website looks like, use the server command:\nhugo server This will give you a local adress which you can copy and paste into your web browser to have a look at.\nI\u0026rsquo;m happy with my post - what next? When you are finished with your post, commit your markdown file with git and push it to the blog repository (not covered in this post).\n","description":"","id":8,"section":"post","tags":["hugo","markdown"],"title":"A beginner's guide to making new posts with Hugo","uri":"https://merrimanlab.github.io/post/2020-10-15-making-posts/"},{"content":"Config files, sometimes referred to as dot-files, are files that you can make to customise the way a program behaves. Two such files you might like to create are .bashrc to customise how your bash looks and behaves, and .Rprofile to customise how R looks and behaves. Usually these files live in you home directory (~/) and because they have a \u0026lsquo;.\u0026rsquo; at the start are hidden from view by default but in bash you can view these hidden files with ls -A ~/.\nBash Bash profile for login .bashrc is the common file that controls your bash set up. Some systems (such as MacOS) also have a file .bash_profile. If your system uses the .bash_profile file, you can make it refer to .bashrc by having this as the contents of .bash_profile:\n[[ -r ~/.bashrc ]] \u0026amp;\u0026amp; . ~/.bashrc In the .bashrc file it is useful to set a customised prompt, set variables that are useful - e.g. MODULEPATH to define where module looks for installed software - and set up some custom commands (aliases) to make common tasks easier.\nCustom prompt Creating your own prompt in bash can be really useful rather than having a straight $. http://ezprompt.net provides a nice way of modifying your prompt and providing the code to add to your .bashrc.\nThings you might want to do:\n add your username add the hostname (the name of the computer) add the current directory add the full path to the current directory have colour  Exported variables Exporting variables is a useful way for defining environmental settings. Often this is setting a bash variable to tell programs where to look for things. This website has a few examples of bash variables (https://www.thegeekstuff.com/2010/08/bash-shell-builtin-commands/).\nIt is useful to include the MODULEAPTH and RSTUDIO_PANDOC variables below.\nSetting MODULEPATH for module For instance on the server to be able to make use of the module system, you\u0026rsquo;ll need to add to you .bashrc file:\nexport MODULEPATH=/Volumes/scratch/software/modules:$MODULEPATH This lets module know where to look for the software modules that are installed/configured.\nRmarkdown Pandoc A useful one on the server, is defining where R is going to look for pandoc for compiling RMarkdown documents.\nI have the following in my .bashrc file\nexport RSTUDIO_PANDOC=/usr/lib/rstudio-server/bin/pandoc When I then open R on the server, the value of that variable is then passed and set to the equivalent in R, and R then knows that I want to use pandoc found at that path. This is important because there might be another instance of pandoc that is available on your PATH. RSTUDIO_PANDOC is the name that R has specified to use if you want to customise which pandoc is used.\nBetter bash history Bash records your history as it goes but if you are operating across multiple windows it doesn\u0026rsquo;t work the way you would hope for - e.g. it is only recorded from a single given session, even if you work in multiple. PROMPT_COMMAND is a bash variable that is run as part of running commands. This particular one is designed to time and date stamp commands (not run as root) and their working directory into a daily log file. The logs live in ~/.logs/ so this needs to be made for the command to run mkdir -p ~/.logs.\nexport PROMPT_COMMAND='if [ \u0026quot;$(id -u)\u0026quot; -ne 0 ]; then echo \u0026quot;$(date \u0026quot;+%Y-%m-%d.%H:%M:%S\u0026quot;) $(pwd) $(history 1)\u0026quot; \u0026gt;\u0026gt; ~/.logs/bash-history-$(date \u0026quot;+%Y-%m-%d\u0026quot;).log; fi' If I want to search my logs I can use grep \u0026lt;command\u0026gt; ~/.logs/* and it will tell me all the times and directories I ran a command, and how I ran it. The history in these log files is made up of all commands you run on the computer, regardless of how many terminal windows you have open.\nAliases Aliases can be quite useful for common commands and arguments you run.\nFor instance I have aliases set up to ssh onto the server and connect to a tmux session if one is already running.\nalias merritmux1='ssh -t biocmerriserver1 tmux attach' This particular one does have to have your ssh config set up so that the details for biocmerriserver\nIt\u0026rsquo;s based on the setup that is required for logging into NeSI (https://support.nesi.org.nz/hc/en-gb/articles/360000625535-Standard-Terminal-Setup)\n In a new local terminal run; mkdir -p ~/.ssh/sockets this will create a hidden file in your home directory to store socket configurations. Open your ssh config file with nano ~/.ssh/config and add the following (replacing  with your username):  Host * ControlMaster auto ControlPath ~/.ssh/sockets/ssh_mux_%h_%p_%r ControlPersist 1 Host biochemcompute User \u0026lt;username\u0026gt; HostName biochemcompute.uod.otago.ac.nz ForwardX11 yes ForwardX11Trusted yes ServerAliveInterval 300 ServerAliveCountMax 2 Creating a ssh Config You can add additional host entries by copying that of biochemcompute and modifying Host and HostName for the other servers you wish to be able to log into.\n Close and save with \u0026lt;ctrl\u0026gt; + x, y, \u0026lt;Enter\u0026gt;\n  Ensure the permissions are correct by running chmod 600 ~/.ssh/config.\n  Once you have made this file you can now ssh onto the servers by ssh \u0026lt;Host\u0026gt;, e.g. ssh biochemcompute and the config file takes care of the rest of the details.\nyou can also use it for scp, such as scp biochemcompute:/path/to/your/file /path/to/put/file to copy a file from the server storage to your local machine.\nR The main config file for R is the ~/.Rprofile. You can also have project specific .Rprofiles that live in your R project directories.\nServer .Rprofile example This Rprofile is designed to use the shared libraries on the server.\nEdit the firstname lastname spots\n# set the default cran repository options(repos = c(CRAN = \u0026quot;https://cran.stat.auckland.ac.nz/\u0026quot;)) # sets the libpath to be the shared directory if using R \u0026gt; v4.0, or personal if \u0026lt; v4.0 .libPaths( c(paste0(\u0026quot;/Volumes/scratch/merrimanlab/R/x86_64-pc-linux-gnu-library/\u0026quot;,version$major,\u0026quot;.\u0026quot;, strsplit(version$minor, \u0026quot;\\\\.\u0026quot;)[[1]][1], \u0026quot;/\u0026quot;), # shared merriman library paste0(\u0026quot;~/R/x86_64-\u0026quot;,ifelse(version$major == \u0026quot;4\u0026quot;, \u0026quot;pc\u0026quot;, \u0026quot;redhat\u0026quot;),\u0026quot;-linux-gnu-library/\u0026quot;,version$major,\u0026quot;.\u0026quot;, strsplit(version$minor, \u0026quot;\\\\.\u0026quot;)[[1]][1],\u0026quot;/\u0026quot;) # personal library )) # load 'helper' packages automatically if running # an interactive session - i.e. not a script if (interactive()) { suppressMessages(require(devtools)) suppressMessages(require(usethis)) suppressMessages(require(testthat)) } # warn on partial matches options( warnPartialMatchArgs = TRUE, warnPartialMatchDollar = TRUE, warnPartialMatchAttr = TRUE ) # fancy quotes are annoying and lead to # 'copy + paste' bugs / frustrations options(useFancyQuotes = FALSE) # set some author info that packages use options(\u0026quot;devtools.desc\u0026quot; = list( Author = \u0026quot;firstname lastname\u0026quot;, Maintainer = paste0(\u0026quot;firstname lastname\u0026quot;, \u0026quot; \u0026lt;\u0026quot;, \u0026quot;email address\u0026quot;, \u0026quot;\u0026gt;\u0026quot;), License = \u0026quot;MIT + file LICENSE\u0026quot;, Version = \u0026quot;0.0.1\u0026quot; )) options(\u0026quot;devtools.name\u0026quot; = \u0026quot;firstname lastname\u0026quot;) # use more cores if possible installing packages options(Ncpus = 8) Libraries In general you want to avoid calling libraries that are involved in analyses because this can alter how reproducible your code would be if you passed it to someone else that didn\u0026rsquo;t have your .Rprofile - e.g. don\u0026rsquo;t have library(tidyverse) in you .Rprofile. It can be useful to automatically load helper packages such as devtools and usethis since they aren\u0026rsquo;t used for analysis but are extremely helpful to have loaded when you want to set things up.\n","description":"","id":9,"section":"post","tags":["bash","R","config","tips"],"title":"Config files","uri":"https://merrimanlab.github.io/post/config-files/"},{"content":"Search for file using \u0026ldquo;find\u0026rdquo; command Per man find:\n The find utility recursively descends the directory tree for each path\nlisted, evaluating an expression (composed of the \u0026ldquo;primaries\u0026rdquo; and\n\u0026ldquo;operands\u0026rdquo; listed below) in terms of each file in the tree.\n Search for a file under a directory You can search for a file with specific name like so:\nfind /path/to/search -name \u0026lt;name of file/dir\u0026gt; The default path to search is the current directory ., and it will search recursively until the very end.\nLimit your search to N-depth You may know how \u0026ldquo;deep\u0026rdquo; your file/directory is buried in your home directory, and it may be unnecessary to search recursively down to the bottom.\nYou should add the -maxdepth \u0026lt;N\u0026gt; option to your find command to limit the search depth:\nfind /path/to/search -maxdepth 3 -name \u0026lt;name of file/dir\u0026gt; The above command will search at most three directories below /path/to/search.\nLimit your serach to specific type of files If you want to limit your search to a specific type of file (e.g. only care about directories), then modify the command as below:\nfind /path/to/search -type d -name \u0026lt;name of file/dir\u0026gt; The option -type \u0026lt;type\u0026gt; will limit the search on directories.\nHere is a list of other types you may find useful:\n   Type What it will search     f Regular file   d Directory   l Symbolic link    ","description":"","id":10,"section":"post","tags":["bash"],"title":"Search for file under a directory","uri":"https://merrimanlab.github.io/post/find_file_in_dir/"},{"content":"Merrimanlab Remote Working VPN access Credentials to use are your email/webkiosk\nHow to Install VPN:\nDownload Cisco AnyConnect from here: https://www.otago.ac.nz/its/services/network/otago038027.html\nNew process: https://otago.custhelp.com/app/answers/detail/a_id/2113\nAfter you\u0026rsquo;ve gone through this process every time you want your home internet to pretend it is at uni open Cisco AnyConnect \u0026amp; tell it to connect to UO-VPN-SSL, then just use your internet like usual.\nFor students we will have to request your username be allowed VPN access, dependent on whether the uni devises another acceptable way for you to access our servers.\nServers Need to be on VPN or Uni network to access\nCredentials to use are your Biochem ones, i.e. for printing\nGeneral biochem servers\n biochemcompute.uod.otago.ac.nz biochemcompute1.uod.otago.ac.nz biochemcompute2.otago.ac.nz biochemcompute3.uod.otago.ac.nz  Merriman exclusive\n biocmerriserver1.otago.ac.nz biocmerriserver2.otago.ac.nz  Important XSan directories:\n  Not backed up\n /Volumes/scratch/merrimanlab    Backed up\n /Volumes/archive/merrimanlab /Volumes/userdata/staff_groups/merrimanlab    Check server load Check how much a particular server is getting used by looking at the status webpage:\nIn your web browser use the url http://\u0026lt;server\u0026gt;:19999\nAvoid servers that are above 75% CPU usage if possible. General biochem servers are likely to have the most people trying to use them.\nssh and Tmux Username and password are your biochem credentials\nssh \u0026lt;biochem username\u0026gt;@\u0026lt;server\u0026gt; It would be recommended to use Tmux for operating on the server which lets your session remain running even if you disconnect.\nBasic usage:\n First login  ssh -t \u0026lt;biochem username\u0026gt;@\u0026lt;server\u0026gt; tmux   Subsequent logins  ssh -t \u0026lt;biochem username\u0026gt;@\u0026lt;server\u0026gt; tmux attach    This will let you close disconnect/close your window without your session on the server closing and let you pick up where you left off.\nAdditional tmux commands can be found here: tmux shortcuts \u0026amp; cheatsheet\nData transfer Avoid using scp between your machine and the server while on VPN\nUse instead:\n Globus CloudStor (similar to dropbox) Citrix reciever (student/staff desktop)  Doesn\u0026rsquo;t have access to XSan   OneDrive (inc MS Teams)  Doesn\u0026rsquo;t have access to XSan    Globus settings  Create new Globus account: https://www.globusid.org/create Download Globus Connect Personal. On the File Manager side tab, search in the Collection search bar, search for UoO_Biochemistry and use your biochem credentials to log in. Use Globus Connect Personal GUI to connect to biochem server and transfer files.  How-to article on setting up Globus for file transfer to/from biochem server. (might not be current)\nCloudstor Needs (complex?) further configuration in order to be able to transfer data to/from XSan\nSimilar to dropbox for sending data to/from other people offers 1 TB of storage\nRstudio server Use any of these to use RStudio and operate on data that is stored on the XSan\nPut url in your web browser after connecting to VPN\nhttps://biochemcompute.otago.ac.nz:8787\nhttps://biochemcompute.otago.ac.nz:8787\nhttps://biocmerriserver1.otago.ac.nz:8787\nhttps://biocmerriserver2.otago.ac.nz:8787\nOne of the limitations is that you can only have a single project open at a time and if you use a different server url it disconnects the current server and loads the project up in the new one (possible benefit if the server your start on starts to get used heaps you can migrate servers easily)\nSocial connectivity Zoom How to install Zoom:\nThe uni has made a video here: https://blogs.otago.ac.nz/zoom/how-to-install-zoom/\nWhen (if) zoom lab meetings go ahead I will send around a meeting link for everyone to connect to the zoom call - all you will need to do is click this link \u0026amp; your zoom app should open and ask if you want to link to the meeting.\nFor those whose turn it is to present I will send more info about how to share your slides with everyone too.\nYou will need to check that your computer has a microphone to use zoom - if you do not have a web cam on your computer that is no drama, you should still be able to share your computer screen via zoom (if you\u0026rsquo;re presenting), and see everyone else, we just won\u0026rsquo;t be able to see you. 🙁\nLog in using the \u0026lsquo;SSO\u0026rsquo; option and use \u0026ldquo;otago\u0026rdquo; as the zoom domain. You\u0026rsquo;ll be taken to a Uni log in portal where you use your email/webkiosk credentials\nCreate on demand Zoom meetings Person creating:\n Open Zoom Click \u0026ldquo;Start with Video\u0026rdquo; or \u0026ldquo;Start Without Video\u0026rdquo; Click invite (at bottom) email or copy the url (bottom left of window)  Joining:\n click the shared url  Zoom tips/tricks https://www.groovehq.com/blog/zoom-tips-and-tricks\nSlack Credentials are whatever you used when joining up\nworkspace: merrimanlab.slack.com\nMS Teams This is what the Uni is trying to transition to for things like having shared word/excel documents\nIt is extremely similar to slack except:\n live file sharing/collaboration conversations on documents chat history doesn\u0026rsquo;t have a limit and is saved  ","description":"","id":11,"section":"quickref","tags":["howto"],"title":"Remote Working","uri":"https://merrimanlab.github.io/quickref/remote-working/"},{"content":"On-the-fly LD calculation The Locus Zoom code calculates the LD of the region (+/-500kb) using the specified SNP (usually lead) as the reference variant to calculate the LD with other variants in the region.\nThis is done by calling external tools within R:\n bcftools to extract the relevant region from the 1000 Genomes reference VCF plink to calculate the LD of specified variant with all other variants in the extracted region  This is the default behaviour when you don\u0026rsquo;t provide the LD information to the LZ call.\nCaveats Variants not present in the reference data Though it could be useful at times, on-the-fly LD calculation could be problematic in certain situation.\nFor example, when the lead variant or the variant you want to plot is present in the summary statistics, but not in the 1000 Genomes reference data, the code will terminate with an error.\nPossible solutions are:\n use a different reference panel for LD calculation use a different (surrogate) variant for the LZ plot  Cluttering of work directory Right now, the calculated LD data are saved in the working directory.\nIf you are generating many plots, this may clutter your working directory extremely quickly.\nWe have not yet implemented any option to turn this feature off, but a work around is to:\n Generate all of the LD for your variants before running LZ plot When you run the LZ code, provide the LD information so that it doesn\u0026rsquo;t calculate the LD on the fly  Here is an example of how you would provide LD information for generating multiple LZ plots.\n","description":"","id":12,"section":"docs","tags":null,"title":"How is LD calculated?","uri":"https://merrimanlab.github.io/docs/locuszooms/how_is_ld_calculated/"},{"content":"List of options Compulsory flags: One of snp, gene, or region must be specified to create the plot:\n   Options Description Default value     snp specify the SNP to be annotated (you must also include ignore.lead = TRUE if choosing this option) NA   gene specify the Gene to make the plot around NA   region specify the chromsome region you want to plot (must be specified as c(chr, start, end) NA   data specify the data.frame (or a list of data.frames) to be used in the plot (requires the columns \u0026ldquo;CHR\u0026rdquo;, \u0026ldquo;BP\u0026rdquo;, \u0026ldquo;SNP\u0026rdquo;, and either \u0026ldquo;P\u0026rdquo; or \u0026ldquo;logBF\u0026rdquo;) NULL   genes.data specify a data.frame with gene locations to plot beneath the graph (requires the columns \u0026ldquo;Gene\u0026rdquo;, \u0026ldquo;Chrom\u0026rdquo;, \u0026ldquo;Start\u0026rdquo;, and \u0026ldquo;End\u0026rdquo;) - the UCSC_GRCh37_Genes_UniqueList.txt in this repo can be used for this NA   plot.title specify a title to go above your plot NA   file.name specify a filename for your plot to be saved to NA    Optional flags:    Options Description Default value     ld.file specify a data.frame with LD values relevant to the SNP specified by snp (requires the columns \u0026ldquo;SNP_B\u0026rdquo; and \u0026ldquo;R2\u0026rdquo;) NULL   offset_bp specify how far either side of the snp, gene, or region you want the plot to extend 200000   noncoding when using the UCSC gene list you can specify whether you want to plot the non-coding genes FALSE   plot.type specify the file format of the plot (options are \u0026ldquo;jpg\u0026rdquo; or \u0026ldquo;svg\u0026rdquo;) \u0026ldquo;jpg\u0026rdquo;   nominal specify the nominal significance level to draw on the plot (in -log10(P)    significant specify the significance level to draw on the plot (in -log10(P)    secondary.snp provide the list of secondary SNP IDs (must match IDs in results file) to be highlighted on the plot NA   secondary.label specify whether to label the secondary SNPs on the plot FALSE   genes.pvalue specify a data.frame of p-values (e.g. MAGMA results) associated with each gene (requires the columns \u0026ldquo;Gene\u0026rdquo; and \u0026ldquo;P\u0026rdquo;) NULL   colour.genes specify whether to colour genes based on a p-value provided in gene.pvalue FALSE   population specify the 1000 genomes population to use when calculating LD if ld.file = NULL (options are \u0026ldquo;AFR\u0026rdquo;, \u0026ldquo;AMR\u0026rdquo;, \u0026ldquo;EAS\u0026rdquo;, \u0026ldquo;EUR\u0026rdquo;, \u0026ldquo;SAS\u0026rdquo;, \u0026ldquo;TAMA\u0026rdquo;, and \u0026ldquo;ALL\u0026rdquo;) \u0026ldquo;EUR\u0026rdquo;   sig.type specify whether the y-axis should be labelled as -log10(P) or log10(BF) (options are \u0026ldquo;P\u0026rdquo; or \u0026ldquo;BF\u0026rdquo;) \u0026ldquo;P\u0026rdquo;   nplots specify whether multiple results plots will be saved into your jpeg file (e.g. plot two GWAS results one above another) FALSE   ignore.lead specify whether to ignore the SNP with the smallest P and use the SNP specified by \u0026lsquo;snp\u0026rsquo; to centre the plot FALSE   rsid.check specify whether to check if the SNPs are labelled with rsIDs - should only matter if script is calculating LD for you TRUE    ","description":"","id":13,"section":"docs","tags":null,"title":"List of options","uri":"https://merrimanlab.github.io/docs/locuszooms/list_of_options/"},{"content":"Repo: https://github.com/MerrimanLab/QTL_pipelines\nThis pipeline runs a co-localisation analysis using a list of key SNPs, a GWAS results file, and the GTEx dataset.\nbash cis_eqtl_pipeline.sh my_gwas.txt my_snplist.txt 1000000 8 ","description":"","id":14,"section":"docs","tags":["eqtl"],"title":"cis-eQTL","uri":"https://merrimanlab.github.io/docs/eqtl/cis-eqtl/"},{"content":"VCF Specification\nhttps://vcftools.github.io/specs.html\nPLINK PED/MAP or BED/BIM/FAM\nSpecification\nhttps://www.cog-genomics.org/plink2/formats#bed\nhttp://pngu.mgh.harvard.edu/~purcell/plink/data.shtml#ped\nSAM/BAM Specification\nhttps://samtools.github.io/hts-specs/\nBED and GTF/GFF Specification\nBED http://asia.ensembl.org/info/website/upload/bed.html\nGTF/GFF http://asia.ensembl.org/info/website/upload/gff.html\nFASTA/FASTQ Specification\nFASTA https://en.wikipedia.org/wiki/FASTA_format\nFASTQ https://en.wikipedia.org/wiki/FASTQ_format\n","description":"","id":15,"section":"quickref","tags":[],"title":"Data Formats","uri":"https://merrimanlab.github.io/quickref/data-formats/"},{"content":"Include name, location on server, link to source and when downloaded/created\nSummary    Resource Version Created/Downloaded     1000 Genomes Project Phase3 September 2014/March 2017   Human Reference Sequence GRCh37 (build 37/hg19) tbc   dbSNP 137 tbc   GATK Resource Bundle b.37 tbc   1KGP Impute Panel Phase3 October 2014    Hosted shiny apps    Name URL     Merriman GTEx eQTL browser http://biochemcompute.otago.ac.nz:3838/mik-apps/QTLBrowser/    Web Resources    Name Genome Build Website     ensembl genome browser GRCh37 http://grch37.ensembl.org/index.html   ensembl genome browser GRCh38 http://ensembl.org/index.html   ensembl ftp  ftp://ftp.ensembl.org/pub/   UCSC genome browser GRCh38 https://genome.ucsc.edu/index.html   UK10K genome browser GRCh37 http://www.uk10k.org/dalliance.html   dbSNP GRCh37/38 http://www.ncbi.nlm.nih.gov/projects/SNP/index.html   LocusZoom  http://locuszoom.sph.umich.edu/locuszoom/   eQTL browser  http://www.ncbi.nlm.nih.gov/projects/gap/eqtl/index.cgi   GTEx Portal  http://www.gtexportal.org/home/   Disease Variant Store  https://rvs.u.hpc.mssm.edu/divas/   DAVID  https://david.ncifcrf.gov/home.jsp   Exome Variant Server  http://evs.gs.washington.edu/EVS/   1000 Genomes Project GRCh37 http://1000genomes.org/   1000 Genomes Project ftp  http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/   Sanger Impute Server  https://imputation.sanger.ac.uk/   HapMap Project GRCh36 http://hapmap.ncbi.nlm.nih.gov/   SHEsis  http://analysis.bio-x.cn/myAnalysis.php   SNAP proxy  https://www.broadinstitute.org/mpg/snap/ldsearch.php   Strand files  http://www.well.ox.ac.uk/~wrayner/strand/   Genome Reference Consortium  http://www.ncbi.nlm.nih.gov/projects/genome/assembly/grc/   NCBI Genome ReMapper  http://www.ncbi.nlm.nih.gov/genome/tools/remap#   GWAS Catalog  www.ebi.ac.uk/gwas/   GWAS Central  www.gwascentral.org   UK Biobank  http://biobank.ctsu.ox.ac.uk/crystal/   UK Biobank ICD explorer  http://risteys.broadinstitute.org    1000 Genomes Project Phase 3 release from September 2014 location: /Volumes/archive/merrimanlab/reference_files/VCF/1000Genomes_vcf_files/Phase3_Sept2014\nPhase 3 release from March 2017 location: /Volumes/archive/merrimanlab/reference_files/VCF/1000Genomes_vcf_files/Phase3_March2017\nBoth are in GRCh37 coordinates.\nImpute2 reference panel GRCh37 coordinates\nhttps://mathgen.stats.ox.ac.uk/impute/1000GP_Phase3.html\nHuman Reference Sequence GRCh37 Decoy reference\nDownloaded 5 Aug 2014\nurl: ftp://ftp.1000genomes.ebi.ac.uk:21/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz\nLocation: /Volumes/archive/merrimanlab/reference_files/FASTA/hs37d5/hsd37d5.fa\ndbSNP dbSNP 151 is available in both GRCh37 and GRCh38 genome builds as a vcf at /Volumes/archive/merrimanlab/reference_files/VCF/dbSNP_reference/dbsnp151/\nGRCh37 is from 2018-04-23\nGRCh38/Hg38 is from 2018-04-18\nGATK Resource Bundle Crucial resource for running the GATK.\nMore information: http://gatkforums.broadinstitute.org/discussion/1213/whats-in-the-resource-bundle-and-how-can-i-get-it\nAncestral allele Downloaded 6 Aug 2014\nurl: ftp://ftp.ensembl.org/pub/release-66/fasta/ancestral_alleles/homo_sapiens_ancestor_GRCh37_e66.tar.bz\n/Volumes/archive/merrimanlab/reference_files/Ancestral_Alleles/homo_sapiens_ancestor_GRCh37_e65/\n","description":"","id":16,"section":"quickref","tags":[],"title":"Reference Resources","uri":"https://merrimanlab.github.io/quickref/reference-resources/"},{"content":"Current training resources for the lab\nNovice/Intro: The Carpentries Software Capentry  Shell R Git/Github SQL  Data Carpentry  Data analysis and visualisation in R Best practice spreadsheets for use later in R  Custom made Merriman Lab R tutorial\n Intro lesson Stats lesson Programming lesson ggplot2 lesson  Additional: R  dplyr ggplot2 RMySQL Rmarkdown  ","description":"","id":17,"section":"quickref","tags":["howto","tutorials","workshops","reference"],"title":"Training Resources","uri":"https://merrimanlab.github.io/quickref/training-resources/"},{"content":"This guide provides a comprehensive set of steps for the manual curation of genotype calls within Genome Studio. Genome Studio\u0026rsquo;s automatic clustering algorithms are reported to be accurate for ~ 99 % of SNPs. The other ~ 1 % need to be manually reviewed. This guide offers a consistent and logical approach and is aimed at reducing the workload where possible. The steps here are a combination of those published by Guo et al. (2014) and Illumina (2016).\nIn our experience, the steps outlined by Illumina (2016) provide a more logical and complete framework for the curation of autosomal SNPs, than those published by Guo et al. (2014). However, Guo et al. (2014) include more detailed instructions for the curation of haploid SNPs and also include post-quality control steps which are invaluable.\nThis guide is laid out in the following order:\n Load data into Genome Studio Clustering within Genome Studio QC of Haploid SNPs QC of Autosomal SNPs Final Quality Thresholds Exporting data \u0026amp; Post-QC steps  Support Files  human coreExome 24 v1.0 and v1.1 accessed 18/4/2016  References Guo, Yan, Jing He, Shilin Zhao, Hui Wu, Xue Zhong, Quanhu Sheng, David C. Samuels, Yu Shyr, and Jirong Long. \u0026ldquo;Illumina human exome genotyping array clustering and quality control.\u0026rdquo; nature protocols 9, no. 11 (2014): 2643-2662.\nIllumina (2016). Infinium Genotyping Data Analysis. [Technical Data Sheet]. Retrieved 18 January, 2016 from http://www.illumina.com/Documents/products/technotes/technote_infinium_genotyping_data_analysis.pdf\n1. Load data into Genome Studio Follow Step 1 of Guo et al. (2014).\n2. Clustering within Genome Studio Follow Steps 2 to 6 of Guo et al. (2014).\nBriefly:\n2) Auto clustering 3) Filter samples with a call-rate \u0026lt;94.5% 4) Exclude these samples - update SNP statistics 5) Unselect \u0026quot;show excluded samples\u0026quot; in the cluster graph 6) Exclude all samples with call-rate \u0026lt;98.5% and re cluster - don't update statistics  Important: Step 6 is essential. If you skip Step 6 you will end up with thousands of SNPs (which require manual fixing) with false AB clusters such as shown below.\nOur own experience suggests that these mis-called AB clusters are almost exclusively due to troublesome samples with call rate \u0026lt; 0.99. Excluding these and reclustering places the AB cluster back in the middle of the plot and avoids this problem.\n3. QC of Haploid SNPs To speed up the QC process we deviate slightly from Guo et al. (2014) for the QC of the Haploid chromosomes.\nStep 3a): In \u0026lsquo;Samples Table\u0026rsquo;, sort samples Gender and select all the Male samples. These should now be highlighted in yellow in the SNP Graph. All Female samples should be coloured according to their genotype.\nStep 3b): Follow steps 12 - 17 of Guo et al. (2014).\nNOTE: you will need to edit the PAR_SNPs.txt file. Open this file and add the following column headers: Name, PAR.\nStep 3c): QC of X Chromosome\na. Follow step 18 Guo _et al._ (2014). [Filter: CHR = X AND PAR != 1] - If you have the Male samples selected, the bright yellow points stand out really clearly. - You can then check all of the X Chromosome SNPs by ordering by ABFreq, starting at the top and rapidly scanning through the SNPs looking for yellow areas in the center of the plot. - We recommend reviewing all of the X Chromosome SNPs with an ABFreq \u0026gt; 0, though it may be possible to stop prior to this ~ ABFreq \u0026lt; 0.2. Scanning through the remainder however will only take a couple of minutes, so is worthwhile. b. Change the SNP filter of CHR = X and PAR = 1 to check all the pseudo autosomal SNPs labelled as the X chromosome. These should look similar to a normal autosomal SNP, check the clusters are well defined, if not zero the selected SNP.  Step 3d): QC of Y Chromosome\nIf you follow Guo et al. (2014), this step will take you a couple of hours. To speed this up, we suggest the following:\na. In the 'SNP Table' change the filter to [CHR = Y AND PAR != 1] OR [CHR = 0 AND Name \u0026quot;has\u0026quot; Y] b. In the 'Sample Table' select all of the Female samples. Right click and exclude these samples. **NOTE:** that you do not need to update the Sample or heritability statistics if prompted. Doing so would take quite a while, and as we are adding the females back in later, is not necessary. c. In the 'SNP Table' select all SNPs (these should only be the Y chromosome SNPs) d. Right click the selected SNPs and \u0026quot;Recluster Selected SNPs\u0026quot;. This may take a few minutes, but it will hopefully remove a large portion of poorly clustered SNPs When prompted, update the SNP statistics. e. In the 'Samples Table' select all Female samples with a call rate \u0026gt;98.5% (the ones we excluded in \u0026quot;b\u0026quot;) and \u0026quot;Include\u0026quot; these again. Once again, there is no need to update the sample and heritability statistics if prompted. f. Follow Step 19 Guo _et al._ (2014). (NB/ Guo _et al._ have a typo, sort by call freq not call rate) f. Add a new column to the SNP Table that estimates the Male Call Freq (#calls/~#men) for Y Chromosome SNPs. Double check this value is \u0026gt; 95% for all Y Chromosome SNPs. g. Change the SNP filter to CHR = Y and PAR = 1 to check all the pseudo autosomal SNPs on the Y chromosome. These should look similar to a normal autosomal SNP, check the clusters are well defined, if not zero the selected SNP.  Step 3e): Follow Step 20 \u0026amp; 21 Guo et al. (2014). (NB/ Guo et al. has a typo, mitochondria are haploid not diploid)\nNOTE: though not stated, be sure to change the filter to [CHR = MT] OR [CHR = 0 AND Name \u0026ldquo;has\u0026rdquo; MT] OR [CHR = 0 AND Name \u0026ldquo;has\u0026rdquo; Mito].\nThis is the end of the Haploid QC steps. Autosomal QC will be based on the Illumina (2016) protocol. Ignore Steps 22 - 33 of Guo et al. (2014).\n4. QC of Autosomal SNPs BaseFilter: Filter the SNP Table to exclude the X, Y, and MT chromosomes. In addition, apply a filter on Edited = 0 (i.e. only shows SNPs we have not edited). [CHR != X AND CHR != Y AND CHR != MT] AND [CHR != 0 AND Name \u0026ldquo;lacks\u0026rdquo; Y AND Name \u0026ldquo;lacks\u0026rdquo; MT AND Name \u0026ldquo;lacks\u0026rdquo; Mito] AND [Edited = 0]\nNOTE: This filter has been saved to GenomeStudio as \u0026lsquo;autosome base filter\u0026rsquo; and can be easily applied by loading it in the Filter window. It leaves SNPs on the XY chromosome as these are pseudo autosomal SNPs so should be treated similarly.\nWe will refer to this filter as the BaseFilter throughout the rest of this guide.\nStep 4a): Cluster Separation Thresholds\nHere, the objective is to identify the LOWER limit on cluster separation (the point below which \u0026ldquo;the majority of loci are unsuccessful\u0026rdquo; (Illumina, 2016, n.p.). In addition, we will aim to identify an approximate UPPER limit above which all loci are successful. Between these two limits are the SNPs we will have to review.\nsteps referred to in Illumina 2016 are referencing section \u0026ldquo;Evaluating and Editing SNP Cluster Positions\u0026rdquo;\nPart One:\n Sort by ClusterSep (descending) Rapidly scan through SNPs to identify the rough UPPER limit for ClusterSeparation. Once identified, you may adjust the filter if you like. Rapidly scan through the SNPs to identify the rough LOWER limit for ClusterSeparation. Zero all SNPs below this threshold.  Part Two:\n (optional) add LOWER \u0026lt; ClusterSep \u0026lt; UPPER to the BaseFilter Follow Step 2, Illumina (2016)  NOTE: For unambiguous SNPs you may be able to improve the CallFreq by adjusting the cluster positions. We found the following appropriate:\n- CallFreq \u0026lt; 0.93 were reliably poor. These were zeroed unless there was an obvious biological reason the low CallFreq (for example structural polymorphisms). - CallFreq \u0026gt; 0.93 were able to be reliably edited. IMPORTANT: at the end we zero all SNPs with a CallFreq \u0026lt; 0.95 \u0026amp; Edited = 0. If you move a cluster at all, the Edited flag changes from 0 to 1. Therefore, **if you try unsuccessfully to edit a SNP, you must manually ZERO it**.  This is the most subjective step. It is tempting to keep SNPs with CallFreq ~ 0.94 after you have manually edited. However, we recommend that you try to be as impartial as possible here. if you edit a SNP and cannot get the Call Freq \u0026gt; 0.95, then zero it and move on.\nStep 4b): Reset filter to BaseFilter then follow Step 3, Illumina (2016).\nIn addition to Illumina (2016), Table 1 suggests a hard limit: AB R Mean \u0026lt; 0.2 should be zeroed. Regardless of cluster definition, AB R Mean \u0026lt; 0.2 suggests problems with the detection of these SNPs.\nEdit: Filter out SNPs with AB Freq = 0 before performing this step.\nStep 4c): Reset filter to BaseFilter then follow Step 4, Illumina (2016).\nStep 4d): Reset filter to BaseFilter then follow Steps 5 \u0026amp; 6, Illumina (2016) if you have family/relatedness information for your data. If you don\u0026rsquo;t have this info these QC steps can be performed outside Genome Studio.\nStep 4e): Reset filter to BaseFilter then follow Step 7, Illumina (2016)\nStep 4f): Detect False Homozygotes (replaces Step 8, Illumina (2016))\n- To the BaseFilter add: ABFreq = 0 - Sort SNPs by MinorFreq (ascending) - Review SNPs with MinorFreq \u0026lt; 0.05 - 0.1. \u0026quot;A SNP can be edited unless clusters overlap or cannot be separated unambiguously\u0026quot; (Illumina, 2016, n.p.).  Step 4g): Hard Filters on Monomorphic SNPs.\nTable 1 (Illumina (2016)) suggests the following hard filters on Theta values. These thresholds are indicative of detection errors and therefore, of SNPs which cannot be trusted.\n- Reset filter to the BaseFilter then: remove edited = 0, add AAFreq = 1 \u0026amp; AA T Mean \u0026gt; 0.3. Zero these SNPs. - Reset filter to the BaseFilter then: remove edited = 0, add AAFreq = 1 \u0026amp; AA T Dev \u0026gt; 0.06. Zero these SNPs. - Reset filter to the BaseFilter then: remove edited = 0, add BBFreq = 1 \u0026amp; BB T Mean \u0026lt; 0.7. Zero these SNPs. - Reset filter to the BaseFilter then: remove edited = 0, add BBFreq = 1 \u0026amp; BB T Dev \u0026gt; 0.06. Zero these SNPs.  5. Final Quality Thresholds In Step 2 we removed all samples with a Call Rate \u0026lt; 0.99. We will now add all of the samples back in and recalculate the sample / SNP statistics.\nStep 5a): Remove all SNP filters. In the \u0026lsquo;Samples Table\u0026rsquo; select all samples and include these. When prompted, recalculate the sample statistics and sample heritability (this may take a little while depending on the number of samples).\nStep 5b): In the \u0026lsquo;Sample Table\u0026rsquo; sort by Call Rate (ascending). Exclude all samples with a Call Rate \u0026lt; 0.98.\nStep 5c): Final check of SNP CallFreq (make sure no SNP filters are on)\n- Filter all SNPs with CallFreq \u0026lt; 0.95. - Review these SNPs, manually editing where possible.  Step 5d): Hard limit on CallFreq\n- Filter: CallFreq \u0026lt; 0.95 \u0026amp; Chromosome != Y. - Zero these SNPs. - Estimate what a CallFreq \u0026lt; 0.95 for men only would look like in the full group (eg. 2734 men in a group of 4053 people would give a CallFreq of 0.64 in the whole group for a Y chromosome SNP with a CallFreq of 0.95 in men only [2734 * 0.95 /4053]) - Filter: CallFreq \u0026lt; calculated number (eg 0.64) \u0026amp; Chromosome = Y. - Zero these SNPs.  Step 5e): Save the project.\n6. Exporting data \u0026amp; Post-QC steps Follow Steps 34 onwards, Guo et al. (2014).\n","description":"","id":18,"section":"docs","tags":["GenomeStudio"],"title":"Genome Studio QC","uri":"https://merrimanlab.github.io/docs/genome-studio-qc/"},{"content":"Orientation A (sort of) induction for new members to the lab to help them get up and running\nThings that need to be sorted out for physical access  ID card loaded into door access system key (if applicable) Lab health and safety brief Dept health and safety  Comms  email  added to lab list lab meetings   invited to lab Slack merrimanlab.github.io  merrimanlab.github.io is a collation of many how-to\u0026rsquo;s for the lab as well and provides some reference material. It\u0026rsquo;s purpose is to supplement knowledge after asking a question.\nComputer access  Lab computer assigned  Create user   Biochem credentials for printing and server access SNPmax login (if applicable) Github account  create account added to lab Org    Computer setup Once local computer and Biochem accounts have been set up:\n ssh  set up ssh config set up .bashrc set up .Rprofile Introduction to the module system   walk-through of XSan structure and what lives where R and RStudio  make sure gets updated    This post about Config files is extremely useful for reference in setting things up to be easier.\nVery useful introduction courses to get some base level skills that are needed\n Shell Version control using Git/Github Data analysis and visualisation in R Best practice spreadsheets for use later in R Rmarkdown  ","description":"","id":19,"section":"quickref","tags":["howto","tutorials","reference"],"title":"New Lab Member","uri":"https://merrimanlab.github.io/quickref/new-lab-member/"}]